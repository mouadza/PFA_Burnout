{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports + chemins + paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T20:11:48.530175Z",
     "iopub.status.busy": "2025-11-17T20:11:48.529834Z",
     "iopub.status.idle": "2025-11-17T20:12:08.506919Z",
     "shell.execute_reply": "2025-11-17T20:12:08.506354Z",
     "shell.execute_reply.started": "2025-11-17T20:11:48.530156Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 20:11:50.475450: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763410310.690810      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1763410310.754976      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# ...\n",
    "DATASET_DIR = \"/kaggle/input/dataset-root/output\"\n",
    "TRAIN_DIR = os.path.join(DATASET_DIR, \"train\")\n",
    "VAL_DIR   = os.path.join(DATASET_DIR, \"val\")\n",
    "TEST_DIR  = os.path.join(DATASET_DIR, \"test\")\n",
    "\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 32\n",
    "SEED = 42\n",
    "NUM_CLASSES = 3  # alert, non_vigilant, tired"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T20:12:08.508724Z",
     "iopub.status.busy": "2025-11-17T20:12:08.508214Z",
     "iopub.status.idle": "2025-11-17T20:12:13.164299Z",
     "shell.execute_reply": "2025-11-17T20:12:13.163747Z",
     "shell.execute_reply.started": "2025-11-17T20:12:08.508706Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3124 images belonging to 3 classes.\n",
      "Found 389 images belonging to 3 classes.\n",
      "Found 394 images belonging to 3 classes.\n",
      "Classes détectées : {'alert': 0, 'non_vigilant': 1, 'tired': 2}\n",
      "Train: 3124 | Val: 389 | Test: 394\n"
     ]
    }
   ],
   "source": [
    "def get_data_generators():\n",
    "    # TRAIN: normalisation + augmentation légère\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1.0 / 255,\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "    )\n",
    "\n",
    "    # VAL & TEST: juste normalisation (aucune augmentation)\n",
    "    val_test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "    train_gen = train_datagen.flow_from_directory(\n",
    "        TRAIN_DIR,\n",
    "        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=\"categorical\",   # 3 classes → one-hot\n",
    "        shuffle=True,\n",
    "        seed=SEED\n",
    "    )\n",
    "\n",
    "    val_gen = val_test_datagen.flow_from_directory(\n",
    "        VAL_DIR,\n",
    "        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    test_gen = val_test_datagen.flow_from_directory(\n",
    "        TEST_DIR,\n",
    "        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    print(\"Classes détectées :\", train_gen.class_indices)\n",
    "    print(\"Train:\", train_gen.n, \"| Val:\", val_gen.n, \"| Test:\", test_gen.n)\n",
    "\n",
    "    return train_gen, val_gen, test_gen\n",
    "\n",
    "train_gen, val_gen, test_gen = get_data_generators()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle 1 : CNN baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T20:12:13.165414Z",
     "iopub.status.busy": "2025-11-17T20:12:13.165151Z",
     "iopub.status.idle": "2025-11-17T20:12:15.524043Z",
     "shell.execute_reply": "2025-11-17T20:12:15.523307Z",
     "shell.execute_reply.started": "2025-11-17T20:12:13.165387Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1763410334.107604      48 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1763410334.108257      48 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50176</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50176</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,422,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50176\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50176\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m6,422,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m387\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,811,459</span> (25.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,811,459\u001b[0m (25.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,811,459</span> (25.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,811,459\u001b[0m (25.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "\n",
    "        layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D(2,2),\n",
    "\n",
    "        layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D(2,2),\n",
    "\n",
    "        layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D(2,2),\n",
    "\n",
    "        layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D(2,2),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Callbacks + entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T20:12:15.525107Z",
     "iopub.status.busy": "2025-11-17T20:12:15.524814Z",
     "iopub.status.idle": "2025-11-17T20:26:28.799716Z",
     "shell.execute_reply": "2025-11-17T20:26:28.798922Z",
     "shell.execute_reply.started": "2025-11-17T20:12:15.525079Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1763410339.802860     113 service.cc:148] XLA service 0x7f68e800d530 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1763410339.803949     113 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1763410339.803969     113 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1763410340.145577     113 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 2/98\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - accuracy: 0.2578 - loss: 1.1107 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1763410345.905779     113 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826ms/step - accuracy: 0.3742 - loss: 1.0970\n",
      "Epoch 1: val_accuracy improved from -inf to 0.41388, saving model to models/fatigue_cnn_baseline.keras\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 923ms/step - accuracy: 0.3744 - loss: 1.0969 - val_accuracy: 0.4139 - val_loss: 1.0534\n",
      "Epoch 2/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520ms/step - accuracy: 0.4495 - loss: 1.0498\n",
      "Epoch 2: val_accuracy improved from 0.41388 to 0.53728, saving model to models/fatigue_cnn_baseline.keras\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 556ms/step - accuracy: 0.4498 - loss: 1.0495 - val_accuracy: 0.5373 - val_loss: 0.9168\n",
      "Epoch 3/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512ms/step - accuracy: 0.5172 - loss: 0.9513\n",
      "Epoch 3: val_accuracy improved from 0.53728 to 0.61440, saving model to models/fatigue_cnn_baseline.keras\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 550ms/step - accuracy: 0.5174 - loss: 0.9510 - val_accuracy: 0.6144 - val_loss: 0.7940\n",
      "Epoch 4/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513ms/step - accuracy: 0.6130 - loss: 0.8386\n",
      "Epoch 4: val_accuracy improved from 0.61440 to 0.69923, saving model to models/fatigue_cnn_baseline.keras\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 547ms/step - accuracy: 0.6130 - loss: 0.8385 - val_accuracy: 0.6992 - val_loss: 0.7045\n",
      "Epoch 5/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518ms/step - accuracy: 0.6454 - loss: 0.7700\n",
      "Epoch 5: val_accuracy did not improve from 0.69923\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 550ms/step - accuracy: 0.6455 - loss: 0.7698 - val_accuracy: 0.6889 - val_loss: 0.6907\n",
      "Epoch 6/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511ms/step - accuracy: 0.6802 - loss: 0.7143\n",
      "Epoch 6: val_accuracy improved from 0.69923 to 0.77121, saving model to models/fatigue_cnn_baseline.keras\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 548ms/step - accuracy: 0.6804 - loss: 0.7142 - val_accuracy: 0.7712 - val_loss: 0.5545\n",
      "Epoch 7/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511ms/step - accuracy: 0.7401 - loss: 0.6218\n",
      "Epoch 7: val_accuracy improved from 0.77121 to 0.82005, saving model to models/fatigue_cnn_baseline.keras\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 547ms/step - accuracy: 0.7401 - loss: 0.6217 - val_accuracy: 0.8201 - val_loss: 0.4603\n",
      "Epoch 8/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522ms/step - accuracy: 0.7761 - loss: 0.5624\n",
      "Epoch 8: val_accuracy improved from 0.82005 to 0.86889, saving model to models/fatigue_cnn_baseline.keras\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 557ms/step - accuracy: 0.7760 - loss: 0.5624 - val_accuracy: 0.8689 - val_loss: 0.3800\n",
      "Epoch 9/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516ms/step - accuracy: 0.8286 - loss: 0.4802\n",
      "Epoch 9: val_accuracy improved from 0.86889 to 0.90746, saving model to models/fatigue_cnn_baseline.keras\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 549ms/step - accuracy: 0.8285 - loss: 0.4801 - val_accuracy: 0.9075 - val_loss: 0.2758\n",
      "Epoch 10/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507ms/step - accuracy: 0.8169 - loss: 0.4718\n",
      "Epoch 10: val_accuracy did not improve from 0.90746\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 538ms/step - accuracy: 0.8170 - loss: 0.4718 - val_accuracy: 0.9023 - val_loss: 0.2736\n",
      "Epoch 11/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519ms/step - accuracy: 0.8545 - loss: 0.3857\n",
      "Epoch 11: val_accuracy improved from 0.90746 to 0.92545, saving model to models/fatigue_cnn_baseline.keras\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 554ms/step - accuracy: 0.8546 - loss: 0.3855 - val_accuracy: 0.9254 - val_loss: 0.2066\n",
      "Epoch 12/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508ms/step - accuracy: 0.8808 - loss: 0.3385\n",
      "Epoch 12: val_accuracy did not improve from 0.92545\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 539ms/step - accuracy: 0.8806 - loss: 0.3387 - val_accuracy: 0.9177 - val_loss: 0.2442\n",
      "Epoch 13/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508ms/step - accuracy: 0.8912 - loss: 0.3229\n",
      "Epoch 13: val_accuracy improved from 0.92545 to 0.94859, saving model to models/fatigue_cnn_baseline.keras\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 543ms/step - accuracy: 0.8912 - loss: 0.3227 - val_accuracy: 0.9486 - val_loss: 0.1721\n",
      "Epoch 14/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514ms/step - accuracy: 0.9120 - loss: 0.2532\n",
      "Epoch 14: val_accuracy improved from 0.94859 to 0.95116, saving model to models/fatigue_cnn_baseline.keras\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 549ms/step - accuracy: 0.9119 - loss: 0.2533 - val_accuracy: 0.9512 - val_loss: 0.1421\n",
      "Epoch 15/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516ms/step - accuracy: 0.9011 - loss: 0.2667\n",
      "Epoch 15: val_accuracy improved from 0.95116 to 0.96658, saving model to models/fatigue_cnn_baseline.keras\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 553ms/step - accuracy: 0.9012 - loss: 0.2666 - val_accuracy: 0.9666 - val_loss: 0.1144\n",
      "Restoring model weights from the end of the best epoch: 15.\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    \"models/fatigue_cnn_baseline.keras\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "earlystop_cb = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=15,\n",
    "    validation_data=val_gen,\n",
    "    callbacks=[checkpoint_cb, earlystop_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle 2: EfficientNetB0 (ancienne version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T20:26:28.806169Z",
     "iopub.status.busy": "2025-11-17T20:26:28.800797Z",
     "iopub.status.idle": "2025-11-17T20:26:28.895168Z",
     "shell.execute_reply": "2025-11-17T20:26:28.894651Z",
     "shell.execute_reply.started": "2025-11-17T20:26:28.806148Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3124 images belonging to 3 classes.\n",
      "Found 389 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as effb0_preprocess\n",
    "\n",
    "train_datagen_effb0 = ImageDataGenerator(\n",
    "    preprocessing_function=effb0_preprocess\n",
    ")\n",
    "\n",
    "val_datagen_effb0 = ImageDataGenerator(\n",
    "    preprocessing_function=effb0_preprocess\n",
    ")\n",
    "\n",
    "train_gen_effb0 = train_datagen_effb0.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "val_gen_effb0 = val_datagen_effb0.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "def build_effb0_model():\n",
    "    base = EfficientNetB0(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "    )\n",
    "    base.trainable = False\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        base,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(NUM_CLASSES, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(1e-4),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Callbacks + entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T20:26:28.897272Z",
     "iopub.status.busy": "2025-11-17T20:26:28.897063Z",
     "iopub.status.idle": "2025-11-17T20:33:54.925385Z",
     "shell.execute_reply": "2025-11-17T20:33:54.924749Z",
     "shell.execute_reply.started": "2025-11-17T20:26:28.897256Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Epoch 1/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 473ms/step - accuracy: 0.3386 - loss: 1.2198 - val_accuracy: 0.4242 - val_loss: 1.1111\n",
      "Epoch 2/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 282ms/step - accuracy: 0.3908 - loss: 1.1324 - val_accuracy: 0.4936 - val_loss: 1.0361\n",
      "Epoch 3/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 273ms/step - accuracy: 0.4846 - loss: 1.0308 - val_accuracy: 0.5424 - val_loss: 0.9799\n",
      "Epoch 4/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 273ms/step - accuracy: 0.5236 - loss: 0.9791 - val_accuracy: 0.5578 - val_loss: 0.9364\n",
      "Epoch 5/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 276ms/step - accuracy: 0.5739 - loss: 0.9283 - val_accuracy: 0.6272 - val_loss: 0.8977\n",
      "Epoch 6/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 271ms/step - accuracy: 0.6007 - loss: 0.8894 - val_accuracy: 0.6735 - val_loss: 0.8652\n",
      "Epoch 7/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 275ms/step - accuracy: 0.6130 - loss: 0.8731 - val_accuracy: 0.6812 - val_loss: 0.8376\n",
      "Epoch 8/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 270ms/step - accuracy: 0.6401 - loss: 0.8349 - val_accuracy: 0.7224 - val_loss: 0.8128\n",
      "Epoch 9/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 275ms/step - accuracy: 0.6369 - loss: 0.8356 - val_accuracy: 0.7301 - val_loss: 0.7892\n",
      "Epoch 10/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 278ms/step - accuracy: 0.6635 - loss: 0.7948 - val_accuracy: 0.7481 - val_loss: 0.7687\n",
      "Epoch 11/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 277ms/step - accuracy: 0.6845 - loss: 0.7632 - val_accuracy: 0.7712 - val_loss: 0.7495\n",
      "Epoch 12/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 271ms/step - accuracy: 0.7079 - loss: 0.7439 - val_accuracy: 0.7686 - val_loss: 0.7321\n",
      "Epoch 13/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 276ms/step - accuracy: 0.7081 - loss: 0.7506 - val_accuracy: 0.7815 - val_loss: 0.7152\n",
      "Epoch 14/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 277ms/step - accuracy: 0.7209 - loss: 0.7298 - val_accuracy: 0.7892 - val_loss: 0.6999\n",
      "Epoch 15/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 274ms/step - accuracy: 0.7466 - loss: 0.6881 - val_accuracy: 0.7918 - val_loss: 0.6847\n",
      "Restoring model weights from the end of the best epoch: 15.\n"
     ]
    }
   ],
   "source": [
    "effb0_model = build_effb0_model()\n",
    "\n",
    "checkpoint_effnetb0 = keras.callbacks.ModelCheckpoint(\n",
    "    \"models/efficientnetb0.keras\", save_best_only=True, monitor=\"val_accuracy\"\n",
    ")\n",
    "history_effb0 = effb0_model.fit(\n",
    "    train_gen_effb0,\n",
    "    validation_data=val_gen_effb0,\n",
    "    epochs=15,\n",
    "    callbacks=[checkpoint_effnetb0,earlystop_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle 3 : EfficientNetV2B0 (Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T20:33:54.927068Z",
     "iopub.status.busy": "2025-11-17T20:33:54.926624Z",
     "iopub.status.idle": "2025-11-17T20:33:56.648937Z",
     "shell.execute_reply": "2025-11-17T20:33:56.648365Z",
     "shell.execute_reply.started": "2025-11-17T20:33:54.927049Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0_notop.h5\n",
      "\u001b[1m24274472/24274472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ efficientnetv2-b0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,919,312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,843</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ efficientnetv2-b0 (\u001b[38;5;33mFunctional\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m5,919,312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │         \u001b[38;5;34m3,843\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,923,155</span> (22.60 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,923,155\u001b[0m (22.60 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,843</span> (15.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,843\u001b[0m (15.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,919,312</span> (22.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m5,919,312\u001b[0m (22.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.applications import EfficientNetV2B0\n",
    "\n",
    "def build_efficientnet_model():\n",
    "    # Base pré-entraînée sur ImageNet\n",
    "    base_model = EfficientNetV2B0(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "    )\n",
    "    # On gèle la base au début (on ne l'entraîne pas)\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(NUM_CLASSES, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "effnet_model = build_efficientnet_model()\n",
    "effnet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Callbacks + entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T20:33:56.649895Z",
     "iopub.status.busy": "2025-11-17T20:33:56.649643Z",
     "iopub.status.idle": "2025-11-17T20:41:43.866738Z",
     "shell.execute_reply": "2025-11-17T20:41:43.866163Z",
     "shell.execute_reply.started": "2025-11-17T20:33:56.649868Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602ms/step - accuracy: 0.3472 - loss: 1.1136\n",
      "Epoch 1: val_accuracy improved from -inf to 0.36761, saving model to models/fatigue_effnet_best.keras\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 741ms/step - accuracy: 0.3472 - loss: 1.1136 - val_accuracy: 0.3676 - val_loss: 1.0971\n",
      "Epoch 2/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506ms/step - accuracy: 0.3745 - loss: 1.1035\n",
      "Epoch 2: val_accuracy did not improve from 0.36761\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 540ms/step - accuracy: 0.3744 - loss: 1.1035 - val_accuracy: 0.3676 - val_loss: 1.0958\n",
      "Epoch 3/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511ms/step - accuracy: 0.3344 - loss: 1.1108\n",
      "Epoch 3: val_accuracy did not improve from 0.36761\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 543ms/step - accuracy: 0.3345 - loss: 1.1107 - val_accuracy: 0.3676 - val_loss: 1.0955\n",
      "Epoch 4/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514ms/step - accuracy: 0.3416 - loss: 1.1135\n",
      "Epoch 4: val_accuracy did not improve from 0.36761\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 544ms/step - accuracy: 0.3416 - loss: 1.1135 - val_accuracy: 0.3676 - val_loss: 1.0961\n",
      "Epoch 5/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514ms/step - accuracy: 0.3484 - loss: 1.1061\n",
      "Epoch 5: val_accuracy did not improve from 0.36761\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 546ms/step - accuracy: 0.3484 - loss: 1.1061 - val_accuracy: 0.3676 - val_loss: 1.0967\n",
      "Epoch 6/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508ms/step - accuracy: 0.3555 - loss: 1.1044\n",
      "Epoch 6: val_accuracy did not improve from 0.36761\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 540ms/step - accuracy: 0.3554 - loss: 1.1045 - val_accuracy: 0.3676 - val_loss: 1.0960\n",
      "Epoch 7/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506ms/step - accuracy: 0.3385 - loss: 1.1150\n",
      "Epoch 7: val_accuracy did not improve from 0.36761\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 537ms/step - accuracy: 0.3385 - loss: 1.1150 - val_accuracy: 0.3676 - val_loss: 1.0957\n",
      "Epoch 8/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.3466 - loss: 1.1090\n",
      "Epoch 8: val_accuracy did not improve from 0.36761\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 535ms/step - accuracy: 0.3466 - loss: 1.1089 - val_accuracy: 0.3676 - val_loss: 1.0982\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n"
     ]
    }
   ],
   "source": [
    "# Checkpoint spécifique pour EfficientNet\n",
    "checkpoint_effnet = keras.callbacks.ModelCheckpoint(\n",
    "    \"models/fatigue_effnet_best.keras\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history_effnet = effnet_model.fit(\n",
    "    train_gen,\n",
    "    epochs=15,\n",
    "    validation_data=val_gen,\n",
    "    callbacks=[checkpoint_effnet, earlystop_cb]  # on réutilise earlystop_cb\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T20:41:43.867956Z",
     "iopub.status.busy": "2025-11-17T20:41:43.867737Z",
     "iopub.status.idle": "2025-11-17T20:42:17.331556Z",
     "shell.execute_reply": "2025-11-17T20:42:17.330795Z",
     "shell.execute_reply.started": "2025-11-17T20:41:43.867939Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 798ms/step - accuracy: 0.1261 - loss: 1.1142\n",
      "[EfficientNetV2B0] Test Loss: 1.0971 - Test Accuracy: 0.3680\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 648ms/step\n",
      "\n",
      "Class indices: {'alert': 0, 'non_vigilant': 1, 'tired': 2}\n",
      "\n",
      "Classification report (EfficientNet):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       alert       0.00      0.00      0.00       126\n",
      "non_vigilant       0.00      0.00      0.00       123\n",
      "       tired       0.37      1.00      0.54       145\n",
      "\n",
      "    accuracy                           0.37       394\n",
      "   macro avg       0.12      0.33      0.18       394\n",
      "weighted avg       0.14      0.37      0.20       394\n",
      "\n",
      "Confusion matrix (EfficientNet):\n",
      "[[  0   0 126]\n",
      " [  0   0 123]\n",
      " [  0   0 145]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "best_effnet = keras.models.load_model(\"models/fatigue_effnet_best.keras\")\n",
    "\n",
    "test_loss, test_acc = best_effnet.evaluate(test_gen)\n",
    "print(f\"[EfficientNetV2B0] Test Loss: {test_loss:.4f} - Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "y_prob = best_effnet.predict(test_gen)\n",
    "y_pred = np.argmax(y_prob, axis=1)\n",
    "y_true = test_gen.classes\n",
    "\n",
    "print(\"\\nClass indices:\", test_gen.class_indices)\n",
    "\n",
    "print(\"\\nClassification report (EfficientNet):\")\n",
    "print(classification_report(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    target_names=list(test_gen.class_indices.keys())\n",
    "))\n",
    "\n",
    "print(\"Confusion matrix (EfficientNet):\")\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle 4 : MobileNetV2 (modèle léger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T20:42:17.332449Z",
     "iopub.status.busy": "2025-11-17T20:42:17.332217Z",
     "iopub.status.idle": "2025-11-17T20:42:18.338776Z",
     "shell.execute_reply": "2025-11-17T20:42:18.338173Z",
     "shell.execute_reply.started": "2025-11-17T20:42:17.332424Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ mobilenetv2_1.00_224            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,843</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ mobilenetv2_1.00_224            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │         \u001b[38;5;34m3,843\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,261,827</span> (8.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,261,827\u001b[0m (8.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,843</span> (15.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,843\u001b[0m (15.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "def build_mobilenet_model():\n",
    "    base_model = MobileNetV2(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "    )\n",
    "    base_model.trainable = False  # on gèle la base\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(NUM_CLASSES, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "mobilenet_model = build_mobilenet_model()\n",
    "mobilenet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Callbacks + entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T20:42:18.339724Z",
     "iopub.status.busy": "2025-11-17T20:42:18.339480Z",
     "iopub.status.idle": "2025-11-17T20:55:53.810740Z",
     "shell.execute_reply": "2025-11-17T20:55:53.810074Z",
     "shell.execute_reply.started": "2025-11-17T20:42:18.339697Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533ms/step - accuracy: 0.3404 - loss: 1.3873\n",
      "Epoch 1: val_accuracy improved from -inf to 0.36761, saving model to models/fatigue_mobilenet_best.keras\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 626ms/step - accuracy: 0.3405 - loss: 1.3866 - val_accuracy: 0.3676 - val_loss: 1.1496\n",
      "Epoch 2/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508ms/step - accuracy: 0.3729 - loss: 1.2182\n",
      "Epoch 2: val_accuracy improved from 0.36761 to 0.42416, saving model to models/fatigue_mobilenet_best.keras\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 545ms/step - accuracy: 0.3730 - loss: 1.2180 - val_accuracy: 0.4242 - val_loss: 1.0660\n",
      "Epoch 3/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513ms/step - accuracy: 0.4018 - loss: 1.1699\n",
      "Epoch 3: val_accuracy improved from 0.42416 to 0.46015, saving model to models/fatigue_mobilenet_best.keras\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 548ms/step - accuracy: 0.4019 - loss: 1.1697 - val_accuracy: 0.4602 - val_loss: 1.0098\n",
      "Epoch 4/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510ms/step - accuracy: 0.4565 - loss: 1.0940\n",
      "Epoch 4: val_accuracy improved from 0.46015 to 0.51671, saving model to models/fatigue_mobilenet_best.keras\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 546ms/step - accuracy: 0.4565 - loss: 1.0939 - val_accuracy: 0.5167 - val_loss: 0.9608\n",
      "Epoch 5/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - accuracy: 0.4634 - loss: 1.0623\n",
      "Epoch 5: val_accuracy did not improve from 0.51671\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 533ms/step - accuracy: 0.4635 - loss: 1.0621 - val_accuracy: 0.5141 - val_loss: 0.9394\n",
      "Epoch 6/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501ms/step - accuracy: 0.5057 - loss: 1.0048\n",
      "Epoch 6: val_accuracy improved from 0.51671 to 0.55784, saving model to models/fatigue_mobilenet_best.keras\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 536ms/step - accuracy: 0.5058 - loss: 1.0047 - val_accuracy: 0.5578 - val_loss: 0.8955\n",
      "Epoch 7/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513ms/step - accuracy: 0.5135 - loss: 1.0047\n",
      "Epoch 7: val_accuracy improved from 0.55784 to 0.60411, saving model to models/fatigue_mobilenet_best.keras\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 551ms/step - accuracy: 0.5136 - loss: 1.0046 - val_accuracy: 0.6041 - val_loss: 0.8617\n",
      "Epoch 8/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516ms/step - accuracy: 0.5664 - loss: 0.9210\n",
      "Epoch 8: val_accuracy did not improve from 0.60411\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 549ms/step - accuracy: 0.5664 - loss: 0.9211 - val_accuracy: 0.5913 - val_loss: 0.8399\n",
      "Epoch 9/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508ms/step - accuracy: 0.5572 - loss: 0.9147\n",
      "Epoch 9: val_accuracy improved from 0.60411 to 0.62468, saving model to models/fatigue_mobilenet_best.keras\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 545ms/step - accuracy: 0.5573 - loss: 0.9147 - val_accuracy: 0.6247 - val_loss: 0.8109\n",
      "Epoch 10/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510ms/step - accuracy: 0.5986 - loss: 0.8647\n",
      "Epoch 10: val_accuracy improved from 0.62468 to 0.64267, saving model to models/fatigue_mobilenet_best.keras\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 546ms/step - accuracy: 0.5985 - loss: 0.8648 - val_accuracy: 0.6427 - val_loss: 0.7902\n",
      "Epoch 11/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506ms/step - accuracy: 0.5980 - loss: 0.8683\n",
      "Epoch 11: val_accuracy improved from 0.64267 to 0.66838, saving model to models/fatigue_mobilenet_best.keras\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 543ms/step - accuracy: 0.5980 - loss: 0.8681 - val_accuracy: 0.6684 - val_loss: 0.7734\n",
      "Epoch 12/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - accuracy: 0.6051 - loss: 0.8606\n",
      "Epoch 12: val_accuracy improved from 0.66838 to 0.67866, saving model to models/fatigue_mobilenet_best.keras\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 536ms/step - accuracy: 0.6052 - loss: 0.8605 - val_accuracy: 0.6787 - val_loss: 0.7509\n",
      "Epoch 13/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505ms/step - accuracy: 0.6325 - loss: 0.8185\n",
      "Epoch 13: val_accuracy improved from 0.67866 to 0.69666, saving model to models/fatigue_mobilenet_best.keras\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 543ms/step - accuracy: 0.6325 - loss: 0.8184 - val_accuracy: 0.6967 - val_loss: 0.7358\n",
      "Epoch 14/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505ms/step - accuracy: 0.6357 - loss: 0.8024\n",
      "Epoch 14: val_accuracy improved from 0.69666 to 0.71465, saving model to models/fatigue_mobilenet_best.keras\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 540ms/step - accuracy: 0.6357 - loss: 0.8024 - val_accuracy: 0.7147 - val_loss: 0.7172\n",
      "Epoch 15/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506ms/step - accuracy: 0.6454 - loss: 0.8031\n",
      "Epoch 15: val_accuracy improved from 0.71465 to 0.72494, saving model to models/fatigue_mobilenet_best.keras\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 542ms/step - accuracy: 0.6454 - loss: 0.8029 - val_accuracy: 0.7249 - val_loss: 0.7024\n",
      "Restoring model weights from the end of the best epoch: 15.\n"
     ]
    }
   ],
   "source": [
    "checkpoint_mobilenet = keras.callbacks.ModelCheckpoint(\n",
    "    \"models/fatigue_mobilenet_best.keras\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history_mobilenet = mobilenet_model.fit(\n",
    "    train_gen,\n",
    "    epochs=15,\n",
    "    validation_data=val_gen,\n",
    "    callbacks=[checkpoint_mobilenet, earlystop_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T20:55:53.811721Z",
     "iopub.status.busy": "2025-11-17T20:55:53.811486Z",
     "iopub.status.idle": "2025-11-17T20:56:13.536910Z",
     "shell.execute_reply": "2025-11-17T20:56:13.536271Z",
     "shell.execute_reply.started": "2025-11-17T20:55:53.811698Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 436ms/step - accuracy: 0.7148 - loss: 0.7495\n",
      "[MobileNetV2] Test Loss: 0.7520 - Test Accuracy: 0.7005\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 445ms/step\n",
      "\n",
      "Classification report (MobileNet):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       alert       0.65      0.71      0.68       126\n",
      "non_vigilant       0.64      0.71      0.67       123\n",
      "       tired       0.83      0.69      0.75       145\n",
      "\n",
      "    accuracy                           0.70       394\n",
      "   macro avg       0.71      0.70      0.70       394\n",
      "weighted avg       0.71      0.70      0.70       394\n",
      "\n",
      "Confusion matrix (MobileNet):\n",
      "[[ 89  26  11]\n",
      " [ 26  87  10]\n",
      " [ 22  23 100]]\n"
     ]
    }
   ],
   "source": [
    "best_mobilenet = keras.models.load_model(\"models/fatigue_mobilenet_best.keras\")\n",
    "\n",
    "test_loss, test_acc = best_mobilenet.evaluate(test_gen)\n",
    "print(f\"[MobileNetV2] Test Loss: {test_loss:.4f} - Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "y_prob = best_mobilenet.predict(test_gen)\n",
    "y_pred = np.argmax(y_prob, axis=1)\n",
    "y_true = test_gen.classes\n",
    "\n",
    "print(\"\\nClassification report (MobileNet):\")\n",
    "print(classification_report(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    target_names=list(test_gen.class_indices.keys())\n",
    "))\n",
    "\n",
    "print(\"Confusion matrix (MobileNet):\")\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle 5: ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T20:56:13.538024Z",
     "iopub.status.busy": "2025-11-17T20:56:13.537838Z",
     "iopub.status.idle": "2025-11-17T20:56:15.376271Z",
     "shell.execute_reply": "2025-11-17T20:56:15.375698Z",
     "shell.execute_reply.started": "2025-11-17T20:56:13.538010Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3124 images belonging to 3 classes.\n",
      "Found 389 images belonging to 3 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94668760/94668760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input as resnet_preprocess\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "\n",
    "train_datagen_res = ImageDataGenerator(\n",
    "    preprocessing_function=resnet_preprocess,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen_res = ImageDataGenerator(\n",
    "    preprocessing_function=resnet_preprocess\n",
    ")\n",
    "\n",
    "train_gen_res = train_datagen_res.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "val_gen_res = val_datagen_res.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "def build_resnet_model():\n",
    "    base = ResNet50V2(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "    )\n",
    "    base.trainable = False\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        base,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(NUM_CLASSES, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(1e-4),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "resnet_model = build_resnet_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Callbacks + entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T20:56:15.377230Z",
     "iopub.status.busy": "2025-11-17T20:56:15.377020Z",
     "iopub.status.idle": "2025-11-17T21:10:25.392152Z",
     "shell.execute_reply": "2025-11-17T21:10:25.391581Z",
     "shell.execute_reply.started": "2025-11-17T20:56:15.377213Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 672ms/step - accuracy: 0.3183 - loss: 1.4488 - val_accuracy: 0.4550 - val_loss: 1.1343\n",
      "Epoch 2/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 552ms/step - accuracy: 0.4003 - loss: 1.2286 - val_accuracy: 0.5167 - val_loss: 1.0271\n",
      "Epoch 3/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 561ms/step - accuracy: 0.4611 - loss: 1.1390 - val_accuracy: 0.5424 - val_loss: 0.9563\n",
      "Epoch 4/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 561ms/step - accuracy: 0.4966 - loss: 1.0382 - val_accuracy: 0.5758 - val_loss: 0.9058\n",
      "Epoch 5/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 564ms/step - accuracy: 0.5277 - loss: 0.9786 - val_accuracy: 0.6093 - val_loss: 0.8671\n",
      "Epoch 6/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 565ms/step - accuracy: 0.5520 - loss: 0.9377 - val_accuracy: 0.6427 - val_loss: 0.8282\n",
      "Epoch 7/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 568ms/step - accuracy: 0.5806 - loss: 0.9067 - val_accuracy: 0.6555 - val_loss: 0.7980\n",
      "Epoch 8/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 545ms/step - accuracy: 0.5801 - loss: 0.8910 - val_accuracy: 0.6478 - val_loss: 0.7747\n",
      "Epoch 9/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 557ms/step - accuracy: 0.6032 - loss: 0.8441 - val_accuracy: 0.6632 - val_loss: 0.7471\n",
      "Epoch 10/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 560ms/step - accuracy: 0.6382 - loss: 0.8011 - val_accuracy: 0.6838 - val_loss: 0.7303\n",
      "Epoch 11/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 560ms/step - accuracy: 0.6361 - loss: 0.7842 - val_accuracy: 0.6889 - val_loss: 0.7118\n",
      "Epoch 12/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 565ms/step - accuracy: 0.6696 - loss: 0.7259 - val_accuracy: 0.7095 - val_loss: 0.6888\n",
      "Epoch 13/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 567ms/step - accuracy: 0.6709 - loss: 0.7558 - val_accuracy: 0.7172 - val_loss: 0.6752\n",
      "Epoch 14/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 555ms/step - accuracy: 0.6921 - loss: 0.7214 - val_accuracy: 0.7249 - val_loss: 0.6581\n",
      "Epoch 15/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 554ms/step - accuracy: 0.6804 - loss: 0.7088 - val_accuracy: 0.7378 - val_loss: 0.6478\n",
      "Restoring model weights from the end of the best epoch: 15.\n"
     ]
    }
   ],
   "source": [
    "# ResNet50V2\n",
    "checkpoint_resnet = keras.callbacks.ModelCheckpoint(\n",
    "    \"models/resnet_best.keras\", save_best_only=True, monitor=\"val_accuracy\"\n",
    ")\n",
    "\n",
    "history_resnet = resnet_model.fit(\n",
    "    train_gen_res,\n",
    "    validation_data=val_gen_res,\n",
    "    epochs=15,\n",
    "    callbacks=[checkpoint_resnet, earlystop_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle 6: DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T21:10:25.393542Z",
     "iopub.status.busy": "2025-11-17T21:10:25.393259Z",
     "iopub.status.idle": "2025-11-17T21:10:27.897073Z",
     "shell.execute_reply": "2025-11-17T21:10:27.896511Z",
     "shell.execute_reply.started": "2025-11-17T21:10:25.393520Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3124 images belonging to 3 classes.\n",
      "Found 389 images belonging to 3 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m29084464/29084464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "train_datagen_dense = ImageDataGenerator(\n",
    "    preprocessing_function=densenet_preprocess,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen_dense = ImageDataGenerator(\n",
    "    preprocessing_function=densenet_preprocess\n",
    ")\n",
    "\n",
    "train_gen_dense = train_datagen_dense.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "val_gen_dense = val_datagen_dense.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "def build_densenet_model():\n",
    "    base = DenseNet121(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "    )\n",
    "    base.trainable = False\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        base,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(NUM_CLASSES, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(1e-4),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "densenet_model = build_densenet_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T21:10:27.898025Z",
     "iopub.status.busy": "2025-11-17T21:10:27.897745Z",
     "iopub.status.idle": "2025-11-17T21:25:34.241802Z",
     "shell.execute_reply": "2025-11-17T21:25:34.240969Z",
     "shell.execute_reply.started": "2025-11-17T21:10:27.898002Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 877ms/step - accuracy: 0.3387 - loss: 1.4451 - val_accuracy: 0.3470 - val_loss: 1.2030\n",
      "Epoch 2/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 582ms/step - accuracy: 0.3609 - loss: 1.3049 - val_accuracy: 0.3830 - val_loss: 1.1505\n",
      "Epoch 3/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 583ms/step - accuracy: 0.3812 - loss: 1.2383 - val_accuracy: 0.4139 - val_loss: 1.1132\n",
      "Epoch 4/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 578ms/step - accuracy: 0.4081 - loss: 1.1771 - val_accuracy: 0.4344 - val_loss: 1.0756\n",
      "Epoch 5/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 578ms/step - accuracy: 0.4195 - loss: 1.1602 - val_accuracy: 0.4396 - val_loss: 1.0429\n",
      "Epoch 6/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 580ms/step - accuracy: 0.4380 - loss: 1.1126 - val_accuracy: 0.4679 - val_loss: 1.0137\n",
      "Epoch 7/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 574ms/step - accuracy: 0.4348 - loss: 1.1033 - val_accuracy: 0.5039 - val_loss: 0.9885\n",
      "Epoch 8/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 577ms/step - accuracy: 0.4628 - loss: 1.0512 - val_accuracy: 0.5193 - val_loss: 0.9680\n",
      "Epoch 9/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 573ms/step - accuracy: 0.4971 - loss: 1.0229 - val_accuracy: 0.5296 - val_loss: 0.9475\n",
      "Epoch 10/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 582ms/step - accuracy: 0.4858 - loss: 1.0159 - val_accuracy: 0.5578 - val_loss: 0.9320\n",
      "Epoch 11/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 564ms/step - accuracy: 0.5096 - loss: 0.9926 - val_accuracy: 0.5527 - val_loss: 0.9142\n",
      "Epoch 12/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 575ms/step - accuracy: 0.5062 - loss: 0.9972 - val_accuracy: 0.5733 - val_loss: 0.8993\n",
      "Epoch 13/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 588ms/step - accuracy: 0.5187 - loss: 0.9615 - val_accuracy: 0.6041 - val_loss: 0.8893\n",
      "Epoch 14/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 572ms/step - accuracy: 0.5432 - loss: 0.9316 - val_accuracy: 0.6170 - val_loss: 0.8775\n",
      "Epoch 15/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 577ms/step - accuracy: 0.5453 - loss: 0.9244 - val_accuracy: 0.6067 - val_loss: 0.8594\n",
      "Restoring model weights from the end of the best epoch: 15.\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dense = keras.callbacks.ModelCheckpoint(\n",
    "    \"models/densenet_best.keras\", save_best_only=True, monitor=\"val_accuracy\"\n",
    ")\n",
    "\n",
    "history_dense = densenet_model.fit(\n",
    "    train_gen_dense,\n",
    "    validation_data=val_gen_dense,\n",
    "    epochs=15,\n",
    "    callbacks=[checkpoint_dense, earlystop_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle 6: InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T21:25:34.243219Z",
     "iopub.status.busy": "2025-11-17T21:25:34.242939Z",
     "iopub.status.idle": "2025-11-17T21:25:36.534230Z",
     "shell.execute_reply": "2025-11-17T21:25:36.533634Z",
     "shell.execute_reply.started": "2025-11-17T21:25:34.243192Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3124 images belonging to 3 classes.\n",
      "Found 389 images belonging to 3 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess\n",
    "\n",
    "train_datagen_inc = ImageDataGenerator(\n",
    "    preprocessing_function=inception_preprocess\n",
    ")\n",
    "\n",
    "val_datagen_inc = ImageDataGenerator(\n",
    "    preprocessing_function=inception_preprocess\n",
    ")\n",
    "\n",
    "train_gen_inc = train_datagen_inc.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "val_gen_inc = val_datagen_inc.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "def build_inception_model():\n",
    "    base = InceptionV3(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "    )\n",
    "    base.trainable = False\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        base,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(NUM_CLASSES, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(1e-4),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "inception_model = build_inception_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T21:25:36.536907Z",
     "iopub.status.busy": "2025-11-17T21:25:36.536694Z",
     "iopub.status.idle": "2025-11-17T21:33:21.677093Z",
     "shell.execute_reply": "2025-11-17T21:33:21.676516Z",
     "shell.execute_reply.started": "2025-11-17T21:25:36.536890Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 487ms/step - accuracy: 0.3506 - loss: 1.3687 - val_accuracy: 0.4499 - val_loss: 1.0698\n",
      "Epoch 2/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 296ms/step - accuracy: 0.4184 - loss: 1.2167 - val_accuracy: 0.5270 - val_loss: 0.9807\n",
      "Epoch 3/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 289ms/step - accuracy: 0.4734 - loss: 1.1183 - val_accuracy: 0.5424 - val_loss: 0.9088\n",
      "Epoch 4/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 292ms/step - accuracy: 0.4810 - loss: 1.0522 - val_accuracy: 0.6170 - val_loss: 0.8503\n",
      "Epoch 5/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 290ms/step - accuracy: 0.5323 - loss: 0.9685 - val_accuracy: 0.6658 - val_loss: 0.8054\n",
      "Epoch 6/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 288ms/step - accuracy: 0.5637 - loss: 0.9118 - val_accuracy: 0.6838 - val_loss: 0.7696\n",
      "Epoch 7/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 293ms/step - accuracy: 0.6002 - loss: 0.8653 - val_accuracy: 0.7198 - val_loss: 0.7378\n",
      "Epoch 8/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 291ms/step - accuracy: 0.6005 - loss: 0.8692 - val_accuracy: 0.7481 - val_loss: 0.7145\n",
      "Epoch 9/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 293ms/step - accuracy: 0.6358 - loss: 0.8133 - val_accuracy: 0.7609 - val_loss: 0.6880\n",
      "Epoch 10/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 287ms/step - accuracy: 0.6440 - loss: 0.7856 - val_accuracy: 0.7738 - val_loss: 0.6619\n",
      "Epoch 11/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 294ms/step - accuracy: 0.6736 - loss: 0.7281 - val_accuracy: 0.7866 - val_loss: 0.6389\n",
      "Epoch 12/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 292ms/step - accuracy: 0.6832 - loss: 0.7281 - val_accuracy: 0.7789 - val_loss: 0.6203\n",
      "Epoch 13/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 304ms/step - accuracy: 0.7109 - loss: 0.6856 - val_accuracy: 0.7969 - val_loss: 0.6071\n",
      "Epoch 14/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 296ms/step - accuracy: 0.7264 - loss: 0.6677 - val_accuracy: 0.8123 - val_loss: 0.5876\n",
      "Epoch 15/15\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 280ms/step - accuracy: 0.7492 - loss: 0.6314 - val_accuracy: 0.8098 - val_loss: 0.5722\n",
      "Restoring model weights from the end of the best epoch: 15.\n"
     ]
    }
   ],
   "source": [
    "# InceptionV3\n",
    "checkpoint_inc = keras.callbacks.ModelCheckpoint(\n",
    "    \"models/inceptionv3_best.keras\", save_best_only=True, monitor=\"val_accuracy\"\n",
    ")\n",
    "\n",
    "history_inception = inception_model.fit(\n",
    "    train_gen_inc,\n",
    "    validation_data=val_gen_inc,\n",
    "    epochs=15,\n",
    "    callbacks=[checkpoint_inc, earlystop_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rapport (Comparaison finale des modèles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T21:33:21.678297Z",
     "iopub.status.busy": "2025-11-17T21:33:21.678041Z",
     "iopub.status.idle": "2025-11-17T21:35:00.639249Z",
     "shell.execute_reply": "2025-11-17T21:35:00.638578Z",
     "shell.execute_reply.started": "2025-11-17T21:33:21.678278Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Résumé des performances sur le test set ===\n",
      "CNN baseline       : 0.9772\n",
      "EfficientNetB0     : 0.3680\n",
      "EfficientNetV2B0   : 0.3680\n",
      "MobileNetV2        : 0.7005\n",
      "ResNet50V2         : 0.7411\n",
      "DenseNet121        : 0.5711\n",
      "InceptionV3        : 0.7893\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Résumé des performances sur le test set ===\")\n",
    "\n",
    "# 0. CNN baseline\n",
    "cnn_best = keras.models.load_model(\"models/fatigue_cnn_baseline.keras\")\n",
    "_, acc_cnn = cnn_best.evaluate(test_gen, verbose=0)\n",
    "\n",
    "# 1. EfficientNetB0 (ancienne version)\n",
    "effb0_best = keras.models.load_model(\"models/efficientnetb0.keras\")\n",
    "_, acc_effb0 = effb0_best.evaluate(test_gen, verbose=0)\n",
    "\n",
    "# 2. EfficientNetV2B0 (nouvelle version)\n",
    "effv2_best = keras.models.load_model(\"models/fatigue_effnet_best.keras\")\n",
    "_, acc_effv2 = effv2_best.evaluate(test_gen, verbose=0)\n",
    "\n",
    "# 3. MobileNetV2\n",
    "mobilenet_best = keras.models.load_model(\"models/fatigue_mobilenet_best.keras\")\n",
    "_, acc_mobilenet = mobilenet_best.evaluate(test_gen, verbose=0)\n",
    "\n",
    "# 4. ResNet50V2\n",
    "resnet_best = keras.models.load_model(\"models/resnet_best.keras\")\n",
    "_, acc_resnet = resnet_best.evaluate(test_gen, verbose=0)\n",
    "\n",
    "# 5. DenseNet121\n",
    "densenet_best = keras.models.load_model(\"models/densenet_best.keras\")\n",
    "_, acc_densenet = densenet_best.evaluate(test_gen, verbose=0)\n",
    "\n",
    "# 6. InceptionV3\n",
    "inception_best = keras.models.load_model(\"models/inceptionv3_best.keras\")\n",
    "_, acc_inception = inception_best.evaluate(test_gen, verbose=0)\n",
    "\n",
    "# Affichage formaté\n",
    "results = {\n",
    "    \"CNN baseline\"      : acc_cnn,\n",
    "    \"EfficientNetB0\"    : acc_effb0,\n",
    "    \"EfficientNetV2B0\"  : acc_effv2,\n",
    "    \"MobileNetV2\"       : acc_mobilenet,\n",
    "    \"ResNet50V2\"        : acc_resnet,\n",
    "    \"DenseNet121\"       : acc_densenet,\n",
    "    \"InceptionV3\"       : acc_inception,\n",
    "}\n",
    "\n",
    "for name, acc in results.items():\n",
    "    print(f\"{name:18s} : {acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8709149,
     "sourceId": 13692690,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8712645,
     "sourceId": 13697195,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
